# Discriminating solid masses and cysts in dual-energy digital mammography using a convolutional neural network: Simulation study

Records and experiments of training deep learning model to differentiate solid masses and fluid cysts in dual-enery mammograms using [Monte-Carlo simulation programs](https://github.com/DIDSR/VICTRE_MCGPU/) developed by the FDA with anthropormorphic digital breast phantoms supplied by Christian Graff and mentored by Stephen J. Glick and Andrey Makeev from OSEL/CDRH/DIDSR.

## Results
The model weights which achieved 97.02% validation accuracy (trained for 50 epochs) is located in the best_try folder in the file called [best_try27.h5](./best_try/best_try27.h5). A ResNet architecture was used using (from PyImageSearch) Adrian Rosebrock's implementation with 32 layers and three stages of filters with sizes 64, 128, 256, and 512 ([resnet.py](./resnet.py)). 

## File Structure
The Python program [modelmk1.py](./model1mk.py) is the file we ran to train the model and it produced files saved with the weights from the best validation loss, located in the [best_try](./best_try) folder, and the ending weights of the model after training, located in the [ending_weights](./ending_weights) folder. Graphs of the training and validation loss and accuracy are saved in the [plot](./plot) folder and dictionaries containing the values are saved in the [history](./history) folder in the form of pickle files. The [monitor](./monitor) folder contains .json files and .png graphs which are updated every epoch during training in order to monitor the validation loss curve to ensure the model is not overfitting. In the case where it is, then we are able to stop the model and tune the right hyperparameters to reduce the time spent on training (implemented by Adrian Rosebrock from PyImageSearch). The file [trainingmonitor.py](./pyimagesearch/trainingmonitor.py) is the callback implementation used and is located in the [pyimagesearch](./pyimagesearch) folder. The [onecycle](./onecycle) folder includes the loss values and the learning rate values for one epoch of training in order to find the optimal max learning rate to use during [cyclical learning rate one cycle training](https://github.com/titu1994/keras-one-cycle) as well as corresponding plots of learning rate vs. training loss. The suggested value of the maximum learning rate should be the largest learning rate with lowest loss before the loss explodes or becomes unstable and the values can be generated by running [find_lr.py](./find_lr.py) which uses the LRFinder class in [clr.py](./clr.py). The model then uses cyclical learning rates modified from [fast.ai Jupyter Notebooks](https://github.com/fastai/course-v3/blob/master/nbs/dl2/05_anneal.ipynb) with two cosine functions. 

## Images
Sample images for the validation and training set are located in the [cyst](./cyst) and [mass](./mass) folders. 
